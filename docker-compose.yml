services:
  # Frontend service - Next.js portfolio application
  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
      target: development
    container_name: portfolio-frontend
    ports:
      - "${PORT:-8087}:${PORT:-8087}"
    volumes:
      # Mount source code for hot reloading in development
      - ./frontend:/app
      # Mount knowledge directory for AI chatbot context
      - ./knowledge:/app/knowledge:ro
      # Prevent node_modules from being overwritten by volume mount
      - /app/node_modules
      # Prevent .next from being overwritten
      - /app/.next
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - PORT=${PORT:-8087}
      - HOSTNAME=${HOSTNAME:-0.0.0.0}
      # Logging level (debug, info, warn, error)
      - LOG_LEVEL=${LOG_LEVEL:-info}
      # AI Chatbot - OpenAI Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
    restart: unless-stopped
    profiles:
      - development

  # Production frontend service (use with: docker compose --profile production up)
  frontend-prod:
    build:
      context: .
      dockerfile: frontend/Dockerfile
      target: production
      args:
        # Optional: Provide these to fetch private knowledge repo at build time
        # KNOWLEDGE_REPO format: github.com/username/repo.git (no https://)
        - KNOWLEDGE_REPO=${KNOWLEDGE_REPO:-}
        - GITHUB_TOKEN=${GITHUB_TOKEN:-}
    container_name: portfolio-frontend-prod
    ports:
      - "${PORT:-8087}:${PORT:-8087}"
    environment:
      - NODE_ENV=production
      - PORT=${PORT:-8087}
      - HOSTNAME=${HOSTNAME:-0.0.0.0}
      # Logging level (debug, info, warn, error) - defaults to warn in production
      - LOG_LEVEL=${LOG_LEVEL:-info}
      # AI Chatbot - OpenAI Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
    restart: unless-stopped
    profiles:
      - production
